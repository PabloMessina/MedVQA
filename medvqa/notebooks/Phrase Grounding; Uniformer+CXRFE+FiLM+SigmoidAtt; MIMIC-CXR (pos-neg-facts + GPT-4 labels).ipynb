{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "721b5038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71033fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 1000\n",
      "   max_images_per_batch: 12\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 4.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061106_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: cxrmate-rrg24-uniformer-huggingface\n",
      "   huggingface_model_name: aehrc/cxrmate-rrg24\n",
      "   num_regions: 144\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 12\n",
      "   regions_height: 12\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp__no_grounding\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 4\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [384, 384]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(num_facts=403416)(hash=667,519549387085821745).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: False\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = False\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061106_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: cxrmate-rrg24-uniformer-huggingface\n",
      "  self.global_feat_size = 1024\n",
      "  self.local_feat_size = 512\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], image_size = [384, 384]\n",
      "get_train_transform(): Using normal transforms\n",
      "default_prob = 0.35\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], image_size = [384, 384]\n",
      "Returning transform without augmentation\n",
      "\u001b[93m\u001b[1mWarning: unused kwargs in MIMICCXR_VisualModuleTrainer: {'use_yolov8': False}\u001b[0m\n",
      "len(forbidden_train_dicom_ids) = 0\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mNOTE: Using strong and weak negatives for training...\u001b[0m\n",
      "fact_embeddings.shape = (403416, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 141084.34it/s]\n",
      "Total number of images: 377110\n",
      "len(train_indices) = 368960\n",
      "len(test_indices) = 8150\n",
      "len(set(train_indices) & set(test_indices)) = 0\n",
      "avg_facts_per_image = 508.4071796400694\n",
      "train_num_facts_per_image = 45\n",
      "avg_facts_per_image = 512.7752147239264\n",
      "test_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 12\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 30747\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "len(self.test_fact_dataloader) = 170\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 30747\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 170\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_002719_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_002719_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_197_mimfg_phrcls_loss+mimfg_prc_auc=0.7139.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061106_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)/checkpoint_197_mimfg_phrcls_loss+mimfg_prc_auc=0.7139.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_002719_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.72306, mimfg_phrcls_loss 0.72306, mimfg_prc_auc 0.85793, 346.99 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.75750, mimfg_prc_auc 0.85283, 124.85 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.5804, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.8579, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 1.4383, den = 2.0000, score = 0.7191\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.5690, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.8528, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 1.4218, den = 2.0000, score = 0.7109\u001b[0m\n",
      "\u001b[93mTrain score = 0.7191, Val score = 0.7109, Final score = 0.7113\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_mimfg_phrcls_loss+mimfg_prc_auc=0.7113.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.74691, mimfg_phrcls_loss 0.74691, mimfg_prc_auc 0.85025, 354.87 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.76526, mimfg_prc_auc 0.85224, 119.53 secs\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "loss 0.71082, mimfg_phrcls_loss 0.71082, mimfg_prc_auc 0.85985, 356.76 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.77004, mimfg_prc_auc 0.85381, 142.76 secs\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.74107, mimfg_phrcls_loss 0.74107, mimfg_prc_auc 0.84797, 351.44 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73620, mimfg_prc_auc 0.84876, 143.42 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_4_mimfg_phrcls_loss+mimfg_prc_auc=0.7123.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 0.74128, mimfg_phrcls_loss 0.74128, mimfg_prc_auc 0.85024, 359.97 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.77876, mimfg_prc_auc 0.85205, 149.71 secs\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.74138, mimfg_phrcls_loss 0.74138, mimfg_prc_auc 0.85202, 345.02 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74373, mimfg_prc_auc 0.85405, 152.12 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_6_mimfg_phrcls_loss+mimfg_prc_auc=0.7137.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.72459, mimfg_phrcls_loss 0.72459, mimfg_prc_auc 0.85673, 354.61 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.75462, mimfg_prc_auc 0.85544, 151.77 secs\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.72499, mimfg_phrcls_loss 0.72499, mimfg_prc_auc 0.85710, 346.12 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.75262, mimfg_prc_auc 0.85599, 151.55 secs\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.72114, mimfg_phrcls_loss 0.72114, mimfg_prc_auc 0.85754, 351.31 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74569, mimfg_prc_auc 0.85692, 151.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_mimfg_phrcls_loss+mimfg_prc_auc=0.7151.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.74579, mimfg_phrcls_loss 0.74579, mimfg_prc_auc 0.84707, 361.36 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.78250, mimfg_prc_auc 0.84585, 150.46 secs\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.73021, mimfg_phrcls_loss 0.73021, mimfg_prc_auc 0.85455, 362.37 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.76256, mimfg_prc_auc 0.85562, 149.57 secs\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.73077, mimfg_phrcls_loss 0.73077, mimfg_prc_auc 0.85623, 366.97 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74355, mimfg_prc_auc 0.85538, 147.13 secs\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.71612, mimfg_phrcls_loss 0.71612, mimfg_prc_auc 0.85874, 361.95 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74212, mimfg_prc_auc 0.85732, 146.47 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_13_mimfg_phrcls_loss+mimfg_prc_auc=0.7159.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.73859, mimfg_phrcls_loss 0.73859, mimfg_prc_auc 0.85311, 361.63 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74230, mimfg_prc_auc 0.85784, 146.02 secs\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.74635, mimfg_phrcls_loss 0.74635, mimfg_prc_auc 0.84542, 346.60 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.75702, mimfg_prc_auc 0.84868, 144.37 secs\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.73229, mimfg_phrcls_loss 0.73229, mimfg_prc_auc 0.85404, 355.42 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74940, mimfg_prc_auc 0.85761, 139.48 secs\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.72743, mimfg_phrcls_loss 0.72743, mimfg_prc_auc 0.85509, 365.37 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74696, mimfg_prc_auc 0.85915, 141.32 secs\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.72201, mimfg_phrcls_loss 0.72201, mimfg_prc_auc 0.85902, 360.53 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73745, mimfg_prc_auc 0.85862, 144.57 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_mimfg_phrcls_loss+mimfg_prc_auc=0.7172.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.71807, mimfg_phrcls_loss 0.71807, mimfg_prc_auc 0.86056, 363.62 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73941, mimfg_prc_auc 0.85894, 142.18 secs\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.72676, mimfg_phrcls_loss 0.72676, mimfg_prc_auc 0.85398, 361.53 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.76052, mimfg_prc_auc 0.85316, 140.70 secs\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.72581, mimfg_phrcls_loss 0.72581, mimfg_prc_auc 0.85610, 347.43 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73360, mimfg_prc_auc 0.85823, 144.63 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_21_mimfg_phrcls_loss+mimfg_prc_auc=0.7175.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.72929, mimfg_phrcls_loss 0.72929, mimfg_prc_auc 0.85847, 359.57 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73642, mimfg_prc_auc 0.85878, 143.86 secs\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.71917, mimfg_phrcls_loss 0.71917, mimfg_prc_auc 0.86061, 344.15 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72843, mimfg_prc_auc 0.86009, 142.03 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_23_mimfg_phrcls_loss+mimfg_prc_auc=0.7194.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70653, mimfg_phrcls_loss 0.70653, mimfg_prc_auc 0.86228, 346.10 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73864, mimfg_prc_auc 0.85961, 142.06 secs\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.71683, mimfg_phrcls_loss 0.71683, mimfg_prc_auc 0.85759, 360.14 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70364, mimfg_prc_auc 0.85657, 140.82 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_25_mimfg_phrcls_loss+mimfg_prc_auc=0.7217.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.71675, mimfg_phrcls_loss 0.71675, mimfg_prc_auc 0.85863, 361.68 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73941, mimfg_prc_auc 0.85870, 141.70 secs\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.71476, mimfg_phrcls_loss 0.71476, mimfg_prc_auc 0.86004, 363.39 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73770, mimfg_prc_auc 0.85974, 140.00 secs\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.70934, mimfg_phrcls_loss 0.70934, mimfg_prc_auc 0.86165, 357.61 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73831, mimfg_prc_auc 0.85969, 138.16 secs\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.71281, mimfg_phrcls_loss 0.71281, mimfg_prc_auc 0.86281, 356.20 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72695, mimfg_prc_auc 0.86070, 138.28 secs\n",
      "\u001b[1m---- Epoch 30/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.72278, mimfg_phrcls_loss 0.72278, mimfg_prc_auc 0.85508, 343.34 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.75994, mimfg_prc_auc 0.85578, 138.49 secs\n",
      "\u001b[1m---- Epoch 31/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.72216, mimfg_phrcls_loss 0.72216, mimfg_prc_auc 0.85761, 362.85 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.77316, mimfg_prc_auc 0.85779, 138.50 secs\n",
      "\u001b[1m---- Epoch 32/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.70522, mimfg_phrcls_loss 0.70522, mimfg_prc_auc 0.86318, 351.05 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74183, mimfg_prc_auc 0.86112, 138.50 secs\n",
      "\u001b[1m---- Epoch 33/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.69580, mimfg_phrcls_loss 0.69580, mimfg_prc_auc 0.86687, 359.67 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72664, mimfg_prc_auc 0.86179, 137.46 secs\n",
      "\u001b[1m---- Epoch 34/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70380, mimfg_phrcls_loss 0.70380, mimfg_prc_auc 0.86353, 357.65 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72668, mimfg_prc_auc 0.86172, 137.05 secs\n",
      "\u001b[1m---- Epoch 35/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.73263, mimfg_phrcls_loss 0.73263, mimfg_prc_auc 0.85215, 343.28 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.77966, mimfg_prc_auc 0.85779, 136.61 secs\n",
      "\u001b[1m---- Epoch 36/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.70968, mimfg_phrcls_loss 0.70968, mimfg_prc_auc 0.86202, 363.05 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.76033, mimfg_prc_auc 0.85761, 137.02 secs\n",
      "\u001b[1m---- Epoch 37/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.70470, mimfg_phrcls_loss 0.70470, mimfg_prc_auc 0.86440, 348.15 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72620, mimfg_prc_auc 0.86347, 136.93 secs\n",
      "\u001b[1m---- Epoch 38/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.69671, mimfg_phrcls_loss 0.69671, mimfg_prc_auc 0.86590, 346.72 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73721, mimfg_prc_auc 0.86373, 136.32 secs\n",
      "\u001b[1m---- Epoch 39/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.70034, mimfg_phrcls_loss 0.70034, mimfg_prc_auc 0.86627, 345.45 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72149, mimfg_prc_auc 0.86338, 138.61 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_39_mimfg_phrcls_loss+mimfg_prc_auc=0.7224.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 40/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.71265, mimfg_phrcls_loss 0.71265, mimfg_prc_auc 0.86036, 360.48 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.77053, mimfg_prc_auc 0.85646, 132.63 secs\n",
      "\u001b[1m---- Epoch 41/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.71226, mimfg_phrcls_loss 0.71226, mimfg_prc_auc 0.86218, 348.49 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74225, mimfg_prc_auc 0.85954, 133.82 secs\n",
      "\u001b[1m---- Epoch 42/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.69008, mimfg_phrcls_loss 0.69008, mimfg_prc_auc 0.86721, 361.59 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70796, mimfg_prc_auc 0.86285, 135.96 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_42_mimfg_phrcls_loss+mimfg_prc_auc=0.7244.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 43/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.69018, mimfg_phrcls_loss 0.69018, mimfg_prc_auc 0.86702, 362.69 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71670, mimfg_prc_auc 0.86303, 128.70 secs\n",
      "\u001b[1m---- Epoch 44/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.68898, mimfg_phrcls_loss 0.68898, mimfg_prc_auc 0.86779, 359.90 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72360, mimfg_prc_auc 0.86268, 123.99 secs\n",
      "\u001b[1m---- Epoch 45/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.71547, mimfg_phrcls_loss 0.71547, mimfg_prc_auc 0.85904, 346.88 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.77207, mimfg_prc_auc 0.85903, 129.39 secs\n",
      "\u001b[1m---- Epoch 46/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.70557, mimfg_phrcls_loss 0.70557, mimfg_prc_auc 0.86184, 360.13 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72069, mimfg_prc_auc 0.86382, 127.01 secs\n",
      "\u001b[1m---- Epoch 47/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.68644, mimfg_phrcls_loss 0.68644, mimfg_prc_auc 0.86904, 360.61 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70786, mimfg_prc_auc 0.86488, 131.01 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_47_mimfg_phrcls_loss+mimfg_prc_auc=0.7255.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 48/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.68323, mimfg_phrcls_loss 0.68323, mimfg_prc_auc 0.87026, 360.40 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71913, mimfg_prc_auc 0.86426, 132.83 secs\n",
      "\u001b[1m---- Epoch 49/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.68903, mimfg_phrcls_loss 0.68903, mimfg_prc_auc 0.86789, 358.43 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71957, mimfg_prc_auc 0.86381, 124.82 secs\n",
      "\u001b[1m---- Epoch 50/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.72120, mimfg_phrcls_loss 0.72120, mimfg_prc_auc 0.85682, 362.97 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71507, mimfg_prc_auc 0.86105, 127.08 secs\n",
      "\u001b[1m---- Epoch 51/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.70459, mimfg_phrcls_loss 0.70459, mimfg_prc_auc 0.86359, 358.76 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70606, mimfg_prc_auc 0.86319, 127.24 secs\n",
      "\u001b[1m---- Epoch 52/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.70154, mimfg_phrcls_loss 0.70154, mimfg_prc_auc 0.86280, 363.76 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71457, mimfg_prc_auc 0.86543, 129.43 secs\n",
      "\u001b[1m---- Epoch 53/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.68213, mimfg_phrcls_loss 0.68213, mimfg_prc_auc 0.87277, 362.38 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70904, mimfg_prc_auc 0.86618, 130.23 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_53_mimfg_phrcls_loss+mimfg_prc_auc=0.7261.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 54/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.68817, mimfg_phrcls_loss 0.68817, mimfg_prc_auc 0.86771, 351.83 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71672, mimfg_prc_auc 0.86547, 132.98 secs\n",
      "\u001b[1m---- Epoch 55/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.69601, mimfg_phrcls_loss 0.69601, mimfg_prc_auc 0.86443, 343.07 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.75756, mimfg_prc_auc 0.86062, 135.18 secs\n",
      "\u001b[1m---- Epoch 56/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.70528, mimfg_phrcls_loss 0.70528, mimfg_prc_auc 0.86387, 341.13 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72013, mimfg_prc_auc 0.86381, 129.38 secs\n",
      "\u001b[1m---- Epoch 57/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.69316, mimfg_phrcls_loss 0.69316, mimfg_prc_auc 0.86604, 344.66 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.72038, mimfg_prc_auc 0.86600, 136.95 secs\n",
      "\u001b[1m---- Epoch 58/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.68602, mimfg_phrcls_loss 0.68602, mimfg_prc_auc 0.87008, 359.67 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70329, mimfg_prc_auc 0.86510, 140.32 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_58_mimfg_phrcls_loss+mimfg_prc_auc=0.7264.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 59/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.68095, mimfg_phrcls_loss 0.68095, mimfg_prc_auc 0.86958, 363.08 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71248, mimfg_prc_auc 0.86642, 141.63 secs\n",
      "\u001b[1m---- Epoch 60/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.70404, mimfg_phrcls_loss 0.70404, mimfg_prc_auc 0.86149, 361.67 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74291, mimfg_prc_auc 0.85834, 135.80 secs\n",
      "\u001b[1m---- Epoch 61/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.70123, mimfg_phrcls_loss 0.70123, mimfg_prc_auc 0.86585, 362.71 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74978, mimfg_prc_auc 0.86453, 143.83 secs\n",
      "\u001b[1m---- Epoch 62/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.69091, mimfg_phrcls_loss 0.69091, mimfg_prc_auc 0.86804, 347.44 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70729, mimfg_prc_auc 0.86599, 141.67 secs\n",
      "\u001b[1m---- Epoch 63/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.68051, mimfg_phrcls_loss 0.68051, mimfg_prc_auc 0.87178, 361.92 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71370, mimfg_prc_auc 0.86705, 144.38 secs\n",
      "\u001b[1m---- Epoch 64/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.67349, mimfg_phrcls_loss 0.67349, mimfg_prc_auc 0.87465, 353.37 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70674, mimfg_prc_auc 0.86734, 143.84 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_64_mimfg_phrcls_loss+mimfg_prc_auc=0.7271.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 65/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.69237, mimfg_phrcls_loss 0.69237, mimfg_prc_auc 0.86536, 360.94 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73733, mimfg_prc_auc 0.86003, 145.69 secs\n",
      "\u001b[1m---- Epoch 66/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.69049, mimfg_phrcls_loss 0.69049, mimfg_prc_auc 0.86863, 364.07 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71121, mimfg_prc_auc 0.86534, 147.39 secs\n",
      "\u001b[1m---- Epoch 67/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.68215, mimfg_phrcls_loss 0.68215, mimfg_prc_auc 0.86967, 366.18 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71033, mimfg_prc_auc 0.87047, 147.74 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_67_mimfg_phrcls_loss+mimfg_prc_auc=0.7278.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 68/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.68071, mimfg_phrcls_loss 0.68071, mimfg_prc_auc 0.86989, 363.32 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70702, mimfg_prc_auc 0.86897, 147.78 secs\n",
      "\u001b[1m---- Epoch 69/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.66990, mimfg_phrcls_loss 0.66990, mimfg_prc_auc 0.87603, 366.22 secs\n",
      "(2) Validation stage ...\n",
      "   iteration 25\r"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250203_061106_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--max_images_per_batch 12 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 4.0 \\\n",
    "--raw_image_encoding \"cxrmate-rrg24-uniformer-huggingface\" \\\n",
    "--huggingface_model_name \"aehrc/cxrmate-rrg24\" \\\n",
    "--image_size 384 384 \\\n",
    "--image_local_feat_size 512 \\\n",
    "--num_regions 144 \\\n",
    "--regions_width 12 \\\n",
    "--regions_height 12 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp__no_grounding\" \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(num_facts=403416)(hash=667,519549387085821745).pkl\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6395d780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   epochs: 100\n",
      "   batches_per_epoch: 1000\n",
      "   max_images_per_batch: 12\n",
      "   max_phrases_per_batch: 1000\n",
      "   max_phrases_per_image: 45\n",
      "   val_batch_size_factor: 4.0\n",
      "   checkpoint_folder: None\n",
      "   pretrained_checkpoint_folder_path: /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_002719_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)\n",
      "   pretrained_checkpoint_folder_paths: None\n",
      "   freeze_image_encoder: False\n",
      "   raw_image_encoding: cxrmate-rrg24-uniformer-huggingface\n",
      "   huggingface_model_name: aehrc/cxrmate-rrg24\n",
      "   num_regions: 144\n",
      "   image_local_feat_size: 512\n",
      "   image_encoder_pretrained_weights_path: None\n",
      "   image_encoder_dropout_p: 0\n",
      "   yolov8_model_name_or_path: None\n",
      "   yolov8_model_alias: None\n",
      "   phrase_embedding_size: 128\n",
      "   regions_width: 12\n",
      "   regions_height: 12\n",
      "   qkv_size: None\n",
      "   phrase_grounding_mode: adaptive_film_based_pooling_mlp__no_grounding\n",
      "   phrase_classifier_hidden_size: None\n",
      "   transf_d_model: None\n",
      "   transf_nhead: None\n",
      "   transf_dim_feedforward: None\n",
      "   transf_dropout: 0\n",
      "   transf_num_layers: None\n",
      "   visual_feature_proj_size: None\n",
      "   visual_grounding_hidden_size: 256\n",
      "   phrase_mlp_hidden_dims: [256, 128]\n",
      "   predict_global_alignment: False\n",
      "   alignment_proj_size: None\n",
      "   yolov11_model_name_or_path: None\n",
      "   yolov11_model_alias: None\n",
      "   optimizer_name: adamw\n",
      "   lr: 1e-06\n",
      "   scheduler: exp-warmup+decay+cyclicdecay\n",
      "   lr_decay: 0.76\n",
      "   lr_decay_patience: 2\n",
      "   warmup_and_decay_args: None\n",
      "   warmup_and_cosine_args: None\n",
      "   warmup_decay_and_cyclic_decay_args: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "   gradient_accumulation_steps: 4\n",
      "   override_lr: False\n",
      "   max_grad_norm: None\n",
      "   attention_supervision_loss_weight: 1.0\n",
      "   phrase_classifier_loss_weight: 1.0\n",
      "   foreground_loss_weight: 1.0\n",
      "   background_loss_weight: 1.0\n",
      "   focal_loss_weight: 1.0\n",
      "   bce_loss_weight: 1.0\n",
      "   wbce_loss_weight: 1.0\n",
      "   binary_multilabel_classif_loss_name: focal+bce+npbbce\n",
      "   use_weighted_phrase_classifier_loss: False\n",
      "   cluster_and_label_weights_for_facts_filepath: None\n",
      "   use_attention_regularization_loss: False\n",
      "   use_contrastive_phrase_grounding_loss: False\n",
      "   nt_xent_temperature: 0.1\n",
      "   num_train_workers: 2\n",
      "   num_val_workers: 2\n",
      "   device: GPU\n",
      "   use_amp: True\n",
      "   image_size: [384, 384]\n",
      "   dicom_id_to_pos_neg_facts_filepath: /mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(nf=403416,nl=28,ngpt4=87528)(hash=741,3592138487644435704).pkl\n",
      "   iuxray_image_id_to_pos_neg_facts_filepath: None\n",
      "   mscxr_phrase2embedding_filepath: None\n",
      "   chest_imagenome_bbox_phrase_embeddings_filepath: None\n",
      "   vinbig_phrase_embeddings_filepath: None\n",
      "   chexlocalize_class_phrase_embeddings_filepath: None\n",
      "   chexpert_class_phrase_embeddings_filepath: None\n",
      "   mimiccxr_exclude_noisy_images: False\n",
      "   mimiccxr_facts_weight: 1.0\n",
      "   chest_imagenome_anatlocs_weight: 1.0\n",
      "   mscxr_weight: 1.0\n",
      "   cxrlt2024_weight: 1.0\n",
      "   vinbig_weight: 1.0\n",
      "   chexlocalize_weight: 1.0\n",
      "   chexpert_weight: 1.0\n",
      "   iuxray_weight: 1.0\n",
      "   img_aug_mode: random-color-and-spatial\n",
      "   pos_area_prior: 0.4\n",
      "   neg_area_prior: 0.0\n",
      "   use_mimiccxr_facts_for_train: True\n",
      "   use_mimiccxr_facts_for_test: True\n",
      "   use_mscxr_for_train: False\n",
      "   use_mscxr_for_test: False\n",
      "   use_chest_imagenome_for_train: False\n",
      "   use_chest_imagenome_gold_for_test: False\n",
      "   use_vinbig_for_train: False\n",
      "   use_vinbig_for_test: False\n",
      "   use_chexlocalize_for_train: False\n",
      "   use_chexlocalize_for_test: False\n",
      "   use_chexpert_for_train: False\n",
      "   use_chexpert_for_test: False\n",
      "   use_iuxray_for_train: False\n",
      "   use_iuxray_for_test: False\n",
      "   use_cxrlt2024_challenge_split: False\n",
      "   use_cxrlt2024_custom_labels: False\n",
      "   use_cxrlt2024_official_labels: False\n",
      "   use_all_cxrlt2024_official_labels_for_training: False\n",
      "   vinbig_training_data_mode: train\n",
      "   chexpert_training_data_mode: all\n",
      "   mimiccxr_balance_long_middle_short_tail: False\n",
      "   mimiccxr_long_middle_short_tail_thresholds: (0.02, 0.05)\n",
      "   mimiccxr_report_fact_nli_integrated_data_filepath: None\n",
      "   mimiccxr_use_interpret_cxr_challenge_split: False\n",
      "   mimiccxr_interpret_cxr_challenge_split_filepath: None\n",
      "   iuxray_use_interpret_cxr_challenge_split: False\n",
      "   iuxray_interpret_cxr_challenge_split_filepath: None\n",
      "   chexpert_use_interpret_cxr_challenge_split: False\n",
      "   chexpert_interpret_cxr_challenge_split_filepath: None\n",
      "   chexlocalize_use_interpret_cxr_challenge_split: False\n",
      "   chexlocalize_interpret_cxr_challenge_split_filepath: None\n",
      "   cxrlt2024_custom_dicom_id_to_pos_neg_facts_filepath: None\n",
      "   cxrlt2024_official_training_labels_for_fact_classification_filepath: None\n",
      "   cxrlt2024_do_balanced_sampling: False\n",
      "   do_visual_grounding_with_bbox_regression: False\n",
      "   do_visual_grounding_with_segmentation: False\n",
      "   replace_phrase_embeddings_with_random_vectors: False\n",
      "   use_vinbig_with_modified_labels: False\n",
      "   save: True\n",
      "\u001b[1m\u001b[34m----- Training model from scratch ------\u001b[0m\n",
      "include_loss_weights = False\n",
      "source_image_size_mode: medium_512\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m1) \u001b[0m\u001b[1m\u001b[34mdevice =\u001b[0m \u001b[1m\u001b[34mcuda\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m2) \u001b[0m\u001b[1m\u001b[34mCreating instance of PhraseGrounder ...\u001b[0m\n",
      "\u001b[93mWARNING: Unused kwargs: {'pretrained_checkpoint_folder_path': '/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_002719_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)', 'pretrained_checkpoint_folder_paths': None}\u001b[0m\n",
      "MultiPurposeVisualModule()\n",
      "  Initializing raw_image_encoder: cxrmate-rrg24-uniformer-huggingface\n",
      "  self.global_feat_size = 1024\n",
      "  self.local_feat_size = 512\n",
      "  Initializing auxiliary tasks\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m3) \u001b[0m\u001b[1m\u001b[34mDefining optimizer ...\u001b[0m\n",
      "create_optimizer(): name = adamw\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m4) \u001b[0m\u001b[1m\u001b[34mDefining scheduler ...\u001b[0m\n",
      "Using exp-warmup+decay+cyclicdecay scheduler: 1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\n",
      "1e-06 3 8e-05 5 1e-06 8e-05 5 1e-06\n",
      "self.steps_to_restart = 5\n",
      "self.steps = -1\n",
      "self.initial_lr = 8e-05\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m5) \u001b[0m\u001b[1m\u001b[34mCreating trainer and validator engines ...\u001b[0m\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "GradientAccumulator.__init__(): num_accumulation_steps = 4, max_grad_norm = None\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_NPBBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 npbbce_weight = 0.3333333333333333\n",
      "Focal_BCE_WBCBCE_Loss(): focal_weight = 0.3333333333333333 bce_weight = 0.3333333333333333 wbcbce_weight = 0.3333333333333333\n",
      "foreground_loss_weight: 1.0\n",
      "background_loss_weight: 1.0\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m6) \u001b[0m\u001b[1m\u001b[34mCreating MIMIC-CXR Phrase Grounding Trainer ...\u001b[0m\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], image_size = [384, 384]\n",
      "get_train_transform(): Using normal transforms\n",
      "default_prob = 0.35\n",
      "Returning augmented transforms with mode random-color-and-spatial\n",
      "get_image_transform()\n",
      "  image_size = [384, 384]\n",
      "  mean = [0.485, 0.456, 0.406]\n",
      "  std = [0.229, 0.224, 0.225]\n",
      "Using standard transform (only images, no bounding boxes, no masks)\n",
      "mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225], image_size = [384, 384]\n",
      "Returning transform without augmentation\n",
      "\u001b[93m\u001b[1mWarning: unused kwargs in MIMICCXR_VisualModuleTrainer: {'use_yolov8': False}\u001b[0m\n",
      "len(forbidden_train_dicom_ids) = 0\n",
      "\u001b[1m\u001b[35mPreparing MIMIC-CXR-Facts datasets and dataloaders for training/testing...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mNOTE: Using strong and weak negatives for training...\u001b[0m\n",
      "fact_embeddings.shape = (403416, 128)\n",
      "Using image size mode: medium_512\n",
      "227835it [00:01, 146999.10it/s]\n",
      "Total number of images: 377110\n",
      "len(train_indices) = 368960\n",
      "len(test_indices) = 8150\n",
      "len(set(train_indices) & set(test_indices)) = 0\n",
      "avg_facts_per_image = 508.52087218126627\n",
      "train_num_facts_per_image = 45\n",
      "avg_facts_per_image = 512.7754601226994\n",
      "test_num_facts_per_image = 45\n",
      "\u001b[1mBuilding train fact dataloader...\u001b[0m\n",
      "batch_size = 12\n",
      "Normal (unbalanced) training...\n",
      "len(self.train_fact_dataloader) = 30747\n",
      "\u001b[1mBuilding test fact dataloaders...\u001b[0m\n",
      "len(self.test_fact_dataloader) = 170\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m7) \u001b[0m\u001b[1m\u001b[34mCreating dataloaders ...\u001b[0m\n",
      "len(mimiccxr_trainer.train_fact_dataloader) = 30747\n",
      "len(mimiccxr_trainer.test_fact_dataloader) = 170\n",
      "len(_train_dataloaders) = 1\n",
      "len(_val_dataloaders) = 1\n",
      "_train_weights = [1.0]\n",
      "merged_dataset_name = mim-facts\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m8) \u001b[0m\u001b[1m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m9) \u001b[0m\u001b[1m\u001b[34mDefining learning rate scheduler handler ...\u001b[0m\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m10) \u001b[0m\u001b[1m\u001b[34mDefining checkpoint folder path ...\u001b[0m\n",
      "\u001b[1m\u001b[31mcheckpoint_folder_path =\u001b[0m \u001b[1m\u001b[31m/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_105410_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)\u001b[0m\n",
      "metadata saved to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_105410_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)/metadata.json\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m11) \u001b[0m\u001b[1m\u001b[34mLoading pretrained weights ...\u001b[0m\n",
      "checkpoint_names = ['checkpoint_74_mimfg_phrcls_loss+mimfg_prc_auc=0.7300.pt']\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_002719_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)/checkpoint_74_mimfg_phrcls_loss+mimfg_prc_auc=0.7300.pt\n",
      "Checkpoint successfully loaded!\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m12) \u001b[0m\u001b[1m\u001b[34mDefining log_metrics_handler ...\u001b[0m\n",
      "MetricsLogger :: we'll be logging to /mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_105410_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)/metrics_logs.csv\n",
      "\u001b[1m\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[1m\u001b[34m13) \u001b[0m\u001b[1m\u001b[34mRunning trainer engine ...\u001b[0m\n",
      "\u001b[1m---- Epoch 1/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.66860, mimfg_phrcls_loss 0.66860, mimfg_prc_auc 0.87374, 353.53 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.70003, mimfg_prc_auc 0.86861, 122.70 secs\n",
      "\u001b[93mTrain metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.5993, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.8737, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 1.4730, den = 2.0000, score = 0.7365\u001b[0m\n",
      "\u001b[93mVal metrics:\u001b[0m\n",
      "\u001b[93mmimfg_phrcls_loss: 0.5882, weight = 1.0\u001b[0m\n",
      "\u001b[93mmimfg_prc_auc: 0.8686, weight = 1.0\u001b[0m\n",
      "\u001b[93mnum = 1.4568, den = 2.0000, score = 0.7284\u001b[0m\n",
      "\u001b[93mTrain score = 0.7365, Val score = 0.7284, Final score = 0.7288\u001b[0m\n",
      "\u001b[93mw_train = 0.05, w_val = 0.95\u001b[0m\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_1_mimfg_phrcls_loss+mimfg_prc_auc=0.7288.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 2/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000004) ...\n",
      "loss 0.66479, mimfg_phrcls_loss 0.66479, mimfg_prc_auc 0.87617, 361.48 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69142, mimfg_prc_auc 0.87005, 149.78 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_2_mimfg_phrcls_loss+mimfg_prc_auc=0.7310.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 3/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000019) ...\n",
      "mimfg_phrcls_loss 0.69685, mimfg_prc_auc 0.87010, 154.45 secs\n",
      "\u001b[1m---- Epoch 4/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.69117, mimfg_phrcls_loss 0.69117, mimfg_prc_auc 0.86529, 351.68 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.74616, mimfg_prc_auc 0.86172, 148.05 secs\n",
      "\u001b[1m---- Epoch 5/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000033) ...\n",
      "loss 0.67186, mimfg_phrcls_loss 0.67186, mimfg_prc_auc 0.87203, 364.31 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.71054, mimfg_prc_auc 0.86925, 153.27 secs\n",
      "\u001b[1m---- Epoch 6/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000014) ...\n",
      "loss 0.66796, mimfg_phrcls_loss 0.66796, mimfg_prc_auc 0.87514, 368.05 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69943, mimfg_prc_auc 0.87192, 152.55 secs\n",
      "\u001b[1m---- Epoch 7/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000006) ...\n",
      "loss 0.67410, mimfg_phrcls_loss 0.67410, mimfg_prc_auc 0.87447, 364.93 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69855, mimfg_prc_auc 0.86986, 151.63 secs\n",
      "\u001b[1m---- Epoch 8/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000002) ...\n",
      "loss 0.66021, mimfg_phrcls_loss 0.66021, mimfg_prc_auc 0.87886, 365.85 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69218, mimfg_prc_auc 0.87098, 154.37 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_8_mimfg_phrcls_loss+mimfg_prc_auc=0.7314.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 9/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.65775, mimfg_phrcls_loss 0.65775, mimfg_prc_auc 0.87935, 367.67 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69058, mimfg_prc_auc 0.87071, 156.79 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_9_mimfg_phrcls_loss+mimfg_prc_auc=0.7316.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 10/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.67722, mimfg_phrcls_loss 0.67722, mimfg_prc_auc 0.86967, 365.26 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.67504, mimfg_prc_auc 0.86504, 161.31 secs\n",
      "\u001b[1m---- Epoch 11/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.65588, mimfg_phrcls_loss 0.65588, mimfg_prc_auc 0.87765, 367.16 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68518, mimfg_prc_auc 0.86998, 160.73 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_11_mimfg_phrcls_loss+mimfg_prc_auc=0.7321.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 12/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.66444, mimfg_phrcls_loss 0.66444, mimfg_prc_auc 0.87522, 353.44 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.67750, mimfg_prc_auc 0.87081, 158.46 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_12_mimfg_phrcls_loss+mimfg_prc_auc=0.7337.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 13/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.65923, mimfg_phrcls_loss 0.65923, mimfg_prc_auc 0.87913, 364.62 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68348, mimfg_prc_auc 0.87231, 161.04 secs\n",
      "\u001b[1m---- Epoch 14/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.65758, mimfg_phrcls_loss 0.65758, mimfg_prc_auc 0.87662, 370.78 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69428, mimfg_prc_auc 0.87157, 165.13 secs\n",
      "\u001b[1m---- Epoch 15/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.67824, mimfg_phrcls_loss 0.67824, mimfg_prc_auc 0.86863, 349.60 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73549, mimfg_prc_auc 0.86754, 159.51 secs\n",
      "\u001b[1m---- Epoch 16/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.66968, mimfg_phrcls_loss 0.66968, mimfg_prc_auc 0.87527, 360.35 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69051, mimfg_prc_auc 0.87105, 165.81 secs\n",
      "\u001b[1m---- Epoch 17/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.65300, mimfg_phrcls_loss 0.65300, mimfg_prc_auc 0.88017, 371.32 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68191, mimfg_prc_auc 0.87146, 169.15 secs\n",
      "\u001b[1m---- Epoch 18/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.64851, mimfg_phrcls_loss 0.64851, mimfg_prc_auc 0.88219, 367.06 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.67637, mimfg_prc_auc 0.87280, 171.87 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_18_mimfg_phrcls_loss+mimfg_prc_auc=0.7351.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 19/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.65498, mimfg_phrcls_loss 0.65498, mimfg_prc_auc 0.88003, 357.28 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68547, mimfg_prc_auc 0.87264, 169.48 secs\n",
      "\u001b[1m---- Epoch 20/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.67119, mimfg_phrcls_loss 0.67119, mimfg_prc_auc 0.87199, 369.24 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73695, mimfg_prc_auc 0.86588, 170.72 secs\n",
      "\u001b[1m---- Epoch 21/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.66778, mimfg_phrcls_loss 0.66778, mimfg_prc_auc 0.87619, 380.62 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68654, mimfg_prc_auc 0.87177, 172.18 secs\n",
      "\u001b[1m---- Epoch 22/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.64663, mimfg_phrcls_loss 0.64663, mimfg_prc_auc 0.88009, 365.21 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69242, mimfg_prc_auc 0.87334, 175.66 secs\n",
      "\u001b[1m---- Epoch 23/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.64928, mimfg_phrcls_loss 0.64928, mimfg_prc_auc 0.88161, 374.39 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68252, mimfg_prc_auc 0.87213, 178.02 secs\n",
      "\u001b[1m---- Epoch 24/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.65586, mimfg_phrcls_loss 0.65586, mimfg_prc_auc 0.87823, 372.47 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68262, mimfg_prc_auc 0.87278, 177.28 secs\n",
      "\u001b[1m---- Epoch 25/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.68011, mimfg_phrcls_loss 0.68011, mimfg_prc_auc 0.86970, 370.50 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69878, mimfg_prc_auc 0.86564, 180.48 secs\n",
      "\u001b[1m---- Epoch 26/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.65572, mimfg_phrcls_loss 0.65572, mimfg_prc_auc 0.87737, 372.67 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69034, mimfg_prc_auc 0.87214, 182.73 secs\n",
      "\u001b[1m---- Epoch 27/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.66839, mimfg_phrcls_loss 0.66839, mimfg_prc_auc 0.87593, 361.82 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.69602, mimfg_prc_auc 0.87340, 192.29 secs\n",
      "\u001b[1m---- Epoch 28/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.65639, mimfg_phrcls_loss 0.65639, mimfg_prc_auc 0.87908, 367.59 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68599, mimfg_prc_auc 0.87377, 191.03 secs\n",
      "\u001b[1m---- Epoch 29/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.66017, mimfg_phrcls_loss 0.66017, mimfg_prc_auc 0.87885, 382.57 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68153, mimfg_prc_auc 0.87400, 192.81 secs\n",
      "\u001b[1m---- Epoch 30/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.65877, mimfg_phrcls_loss 0.65877, mimfg_prc_auc 0.87603, 383.19 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.66729, mimfg_prc_auc 0.87081, 192.94 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_30_mimfg_phrcls_loss+mimfg_prc_auc=0.7355.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 31/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.67015, mimfg_phrcls_loss 0.67015, mimfg_prc_auc 0.87515, 375.26 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.67580, mimfg_prc_auc 0.87309, 193.15 secs\n",
      "\u001b[1m---- Epoch 32/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "loss 0.64854, mimfg_phrcls_loss 0.64854, mimfg_prc_auc 0.88103, 379.80 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.67097, mimfg_prc_auc 0.87478, 196.72 secs\n",
      "\u001b[1m\u001b[31mNew checkpoint saved: checkpoint_32_mimfg_phrcls_loss+mimfg_prc_auc=0.7370.pt\u001b[0m\n",
      "\u001b[1m---- Epoch 33/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000003) ...\n",
      "loss 0.63389, mimfg_phrcls_loss 0.63389, mimfg_prc_auc 0.88504, 381.32 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.67672, mimfg_prc_auc 0.87515, 203.09 secs\n",
      "\u001b[1m---- Epoch 34/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000001) ...\n",
      "loss 0.64332, mimfg_phrcls_loss 0.64332, mimfg_prc_auc 0.88309, 378.60 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.67582, mimfg_prc_auc 0.87462, 207.72 secs\n",
      "\u001b[1m---- Epoch 35/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000080) ...\n",
      "loss 0.66392, mimfg_phrcls_loss 0.66392, mimfg_prc_auc 0.87543, 377.84 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.73279, mimfg_prc_auc 0.86939, 197.27 secs\n",
      "\u001b[1m---- Epoch 36/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000027) ...\n",
      "loss 0.65768, mimfg_phrcls_loss 0.65768, mimfg_prc_auc 0.87879, 381.24 secs\n",
      "(2) Validation stage ...\n",
      "mimfg_phrcls_loss 0.68452, mimfg_prc_auc 0.87268, 195.01 secs\n",
      "\u001b[1m---- Epoch 37/100\u001b[0m\n",
      "(1) Training stage (lr = 0.000009) ...\n",
      "^C iteration 36225\n"
     ]
    }
   ],
   "source": [
    "!python ../train_phrase_grounding.py \\\n",
    "--pretrained_checkpoint_folder_path \\\n",
    "\"/mnt/data/pamessina/workspaces/medvqa-workspace/models/phrase_grounding/20250206_002719_mim-facts_PhraseGrounder(aehrc-cxrmate-rrg24-uniformer,AdaptiveFiLM_MLP,128,256,256-128)\" \\\n",
    "--epochs 100 \\\n",
    "--batches_per_epoch 1000 \\\n",
    "--max_images_per_batch 12 \\\n",
    "--max_phrases_per_batch 1000 \\\n",
    "--max_phrases_per_image 45 \\\n",
    "--val_batch_size_factor 4.0 \\\n",
    "--raw_image_encoding \"cxrmate-rrg24-uniformer-huggingface\" \\\n",
    "--huggingface_model_name \"aehrc/cxrmate-rrg24\" \\\n",
    "--image_size 384 384 \\\n",
    "--image_local_feat_size 512 \\\n",
    "--num_regions 144 \\\n",
    "--regions_width 12 \\\n",
    "--regions_height 12 \\\n",
    "--img_aug_mode \"random-color-and-spatial\" \\\n",
    "--phrase_embedding_size 128 \\\n",
    "--phrase_grounding_mode \"adaptive_film_based_pooling_mlp__no_grounding\" \\\n",
    "--visual_grounding_hidden_size 256 \\\n",
    "--phrase_mlp_hidden_dims 256 128 \\\n",
    "--num_train_workers 2 \\\n",
    "--num_val_workers 2 \\\n",
    "--gradient_accumulation_steps 4 \\\n",
    "--optimizer_name \"adamw\" \\\n",
    "--scheduler \"exp-warmup+decay+cyclicdecay\" \\\n",
    "--lr 1e-6 \\\n",
    "--warmup_decay_and_cyclic_decay_args \"1e-6,3,8e-5,5,1e-6,8e-5,5,1e-6\" \\\n",
    "--binary_multilabel_classif_loss_name \"focal+bce+npbbce\" \\\n",
    "--use_mimiccxr_facts_for_train \\\n",
    "--use_mimiccxr_facts_for_test \\\n",
    "--dicom_id_to_pos_neg_facts_filepath \\\n",
    "\"/mnt/data/pamessina_folder_backup_15_10_24/pamessina/medvqa-workspace/cache/mimiccxr_dicom_id_to_pos_neg_facts_with_GPT4_mined_labels(nf=403416,nl=28,ngpt4=87528)(hash=741,3592138487644435704).pkl\" \\\n",
    "--use_amp \\\n",
    "--save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
