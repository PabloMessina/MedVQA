{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medvqa.evaluation.report_generation import get_report_level_metrics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: models/vqa/20221231_010452_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 3\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "   save_for_error_analysis: True\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_010452_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using default transform\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = [256, 256], use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_81_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5723.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_010452_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_81_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5723.pt\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_010452_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_81_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5723.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = ground-truth\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053;report_eval_mode=ground-truth).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 32697, len(set(self.report_ids)) = 3258\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 32697, len(set(self.report_ids)) = 3258\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "create_densenet121_feature_extractor()\n",
      "   drop_rate: 0.0\n",
      "DenseNet121's pretrained weights loaded from ImageNet\n",
      "  self.global_feat_size = 2048\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(dense121+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 32697\n",
      "len(dataloader) = 205\n",
      "Evaluating model ...\n",
      "oracc 0.99722, chxlmicf1 0.59133, chxlmacf1 0.49225, chxlacc 0.71759, chxlrocaucmic 0.81556, chxlrocaucmac 0.76352, qlmacf1 0.22367, 82.88 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3258, len(gt_reports)=3258\n",
      "Cache successfully loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=813, chunk_size=813\n",
      "chunk: i=1, b=813, e=1626, chunk_size=813\n",
      "chunk: i=2, b=1626, e=2439, chunk_size=813\n",
      "chunk: i=3, b=2439, e=3252, chunk_size=810\n",
      "\t#### process 1: running chexpert labeler over 813 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_101519_0.262109602717161_0.csv --output_path /data/labeler-output_20230108_101519_0.262109602717161_0.csv\n",
      "\t#### process 2: running chexpert labeler over 813 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_101519_0.262109602717161_1.csv --output_path /data/labeler-output_20230108_101519_0.262109602717161_1.csv\n",
      "\t#### process 3: running chexpert labeler over 813 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_101519_0.262109602717161_2.csv --output_path /data/labeler-output_20230108_101519_0.262109602717161_2.csv\n",
      "\t#### process 4: running chexpert labeler over 810 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_101519_0.262109602717161_3.csv --output_path /data/labeler-output_20230108_101519_0.262109602717161_3.csv\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 656.2689998149872\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 2 finished, elapsed time = 671.5285959243774\n",
      "\t**** process 3 finished, elapsed time = 671.5286991596222\n",
      "\t**** process 4 finished, elapsed time = 671.5287404060364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report-level metrics successfully saved to /mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20221231_010452_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl\n",
      "Report-level results for error analysis successfully saved to /mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20221231_010452_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/mimiccxr_report_results_for_error_analysis(eval_mode=ground-truth).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"models/vqa/20221231_010452_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 3 \\\n",
    "        --max-processes-for-chexpert-labeler 4 \\\n",
    "        --save-for-error-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 3\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "   save_for_error_analysis: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for facebook/vit-mae-base\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_96_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5551.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_96_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5551.pt\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_96_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5551.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = ground-truth\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053;report_eval_mode=ground-truth).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 32697, len(set(self.report_ids)) = 3258\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 32697, len(set(self.report_ids)) = 3258\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "You are using a model of type vit_mae to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at facebook/vit-mae-base were not used when initializing ViTModel: ['decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_embed.weight', 'decoder.mask_token', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_pos_embed', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.6.layernorm_before.bias']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/vit-mae-base and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(facebook/vit-mae-base+onehot+transf)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 32697\n",
      "len(dataloader) = 205\n",
      "Evaluating model ...\n",
      "oracc 0.99641, chxlmicf1 0.57145, chxlmacf1 0.48126, chxlacc 0.69535, chxlrocaucmic 0.79470, chxlrocaucmac 0.75655, qlmacf1 0.21262, 175.39 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3258, len(gt_reports)=3258\n",
      "Cache successfully loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=813, chunk_size=813\n",
      "chunk: i=1, b=813, e=1626, chunk_size=813\n",
      "chunk: i=2, b=1626, e=2439, chunk_size=813\n",
      "chunk: i=3, b=2439, e=3252, chunk_size=811\n",
      "\t#### process 1: running chexpert labeler over 813 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_112802_0.25900267748769845_0.csv --output_path /data/labeler-output_20230108_112802_0.25900267748769845_0.csv\n",
      "\t#### process 2: running chexpert labeler over 813 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_112802_0.25900267748769845_1.csv --output_path /data/labeler-output_20230108_112802_0.25900267748769845_1.csv\n",
      "\t#### process 3: running chexpert labeler over 813 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_112802_0.25900267748769845_2.csv --output_path /data/labeler-output_20230108_112802_0.25900267748769845_2.csv\n",
      "\t#### process 4: running chexpert labeler over 811 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_112802_0.25900267748769845_3.csv --output_path /data/labeler-output_20230108_112802_0.25900267748769845_3.csv\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 836.4732136726379\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 2 finished, elapsed time = 852.8527810573578\n",
      "\t**** process 3 finished, elapsed time = 852.8528561592102\n",
      "\t**** process 4 finished, elapsed time = 852.852890253067\n",
      "Report-level metrics successfully saved to /mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20221231_012821_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 3 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_184840_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 3\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "   save_for_error_analysis: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_184840_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for facebook/vit-mae-base\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_39_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.4782.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_184840_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_39_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.4782.pt\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_184840_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_39_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.4782.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = ground-truth\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053;report_eval_mode=ground-truth).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 32697, len(set(self.report_ids)) = 3258\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 32697, len(set(self.report_ids)) = 3258\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "You are using a model of type vit_mae to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at facebook/vit-mae-base were not used when initializing ViTModel: ['decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_pos_embed', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.mask_token', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.2.layernorm_before.weight']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/vit-mae-base and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Ignore freezing parameter: pooler.dense.weight\n",
      "Ignore freezing parameter: pooler.dense.bias\n",
      "  self.global_feat_size = 768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(facebook/vit-mae-base+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 32697\n",
      "len(dataloader) = 205\n",
      "Evaluating model ...\n",
      "oracc 0.97481, chxlmicf1 0.48361, chxlmacf1 0.40194, chxlacc 0.59442, chxlrocaucmic 0.69026, chxlrocaucmac 0.62477, qlmacf1 0.16343, 200.26 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3258, len(gt_reports)=3258\n",
      "Cache successfully loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=810, chunk_size=810\n",
      "chunk: i=1, b=810, e=1620, chunk_size=810\n",
      "chunk: i=2, b=1620, e=2430, chunk_size=810\n",
      "chunk: i=3, b=2430, e=3240, chunk_size=809\n",
      "\t#### process 1: running chexpert labeler over 810 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_114637_0.7035117353793114_0.csv --output_path /data/labeler-output_20230108_114637_0.7035117353793114_0.csv\n",
      "\t#### process 2: running chexpert labeler over 810 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_114637_0.7035117353793114_1.csv --output_path /data/labeler-output_20230108_114637_0.7035117353793114_1.csv\n",
      "\t#### process 3: running chexpert labeler over 810 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_114637_0.7035117353793114_2.csv --output_path /data/labeler-output_20230108_114637_0.7035117353793114_2.csv\n",
      "\t#### process 4: running chexpert labeler over 809 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_114637_0.7035117353793114_3.csv --output_path /data/labeler-output_20230108_114637_0.7035117353793114_3.csv\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 914.41854429245\n",
      "\t**** process 2 finished, elapsed time = 914.4186961650848\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 3 finished, elapsed time = 916.5478191375732\n",
      "\t**** process 4 finished, elapsed time = 916.5479035377502\n",
      "Report-level metrics successfully saved to /mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20230106_184840_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_184840_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 3 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_172050_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=1_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 3\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "   save_for_error_analysis: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_172050_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=1_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for facebook/vit-mae-base\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_100_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5555.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_172050_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=1_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_100_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5555.pt\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_172050_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=1_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/checkpoint_100_b+chf1+chf1+cD+cxf1+cxf1+ema+gacc+orcc+paf1+paf1+paf1+paf1+qlf1+qlf1+vnf1+vnf1+wmmp=0.5555.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = ground-truth\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053;report_eval_mode=ground-truth).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 32697, len(set(self.report_ids)) = 3258\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 32697, len(set(self.report_ids)) = 3258\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path /mnt/data/pamessina/workspaces/medvqa-workspace/models/mae/20230106_124822_mim+iux+chx+cxr14+vinbig+padchest_VitMAE_dws=1.0,0.05,0.6,0.4,0.4,0.5/checkpoint_40_loss=0.9663.pt\n",
      "You are using a model of type vit_mae to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at facebook/vit-mae-base were not used when initializing ViTModel: ['decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_pos_embed', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_pred.weight', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.mask_token', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.6.intermediate.dense.bias']\n",
      "- This IS expected if you are initializing ViTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/vit-mae-base and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained weights successfully loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/mae/20230106_124822_mim+iux+chx+cxr14+vinbig+padchest_VitMAE_dws=1.0,0.05,0.6,0.4,0.4,0.5/checkpoint_40_loss=0.9663.pt\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(facebook/vit-mae-base+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 32697\n",
      "len(dataloader) = 205\n",
      "Evaluating model ...\n",
      "oracc 0.99699, chxlmicf1 0.57430, chxlmacf1 0.48117, chxlacc 0.69627, chxlrocaucmic 0.79580, chxlrocaucmac 0.75485, qlmacf1 0.21116, 179.10 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3258, len(gt_reports)=3258\n",
      "Cache successfully loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=813, chunk_size=813\n",
      "chunk: i=1, b=813, e=1626, chunk_size=813\n",
      "chunk: i=2, b=1626, e=2439, chunk_size=813\n",
      "chunk: i=3, b=2439, e=3252, chunk_size=810\n",
      "\t#### process 1: running chexpert labeler over 813 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_120548_0.6437397810983503_0.csv --output_path /data/labeler-output_20230108_120548_0.6437397810983503_0.csv\n",
      "\t#### process 2: running chexpert labeler over 813 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_120548_0.6437397810983503_1.csv --output_path /data/labeler-output_20230108_120548_0.6437397810983503_1.csv\n",
      "\t#### process 3: running chexpert labeler over 813 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_120548_0.6437397810983503_2.csv --output_path /data/labeler-output_20230108_120548_0.6437397810983503_2.csv\n",
      "\t#### process 4: running chexpert labeler over 810 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230108_120548_0.6437397810983503_3.csv --output_path /data/labeler-output_20230108_120548_0.6437397810983503_3.csv\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "\t**** process 1 finished, elapsed time = 643.3117597103119\n",
      "\t**** process 2 finished, elapsed time = 643.3119795322418\n",
      "\t**** process 3 finished, elapsed time = 643.3120646476746\n",
      "\t**** process 4 finished, elapsed time = 643.312141418457\n",
      "Report-level metrics successfully saved to /mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20230106_172050_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=1_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230106_172050_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)+padchest(vqa)_oevqa(facebook-vit-mae-base+onehot+transf)_visenc-pretr=1_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4,0.5_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 3 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp\n",
      "   eval_mode: ground-truth\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 3\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 6\n",
      "   save_for_error_analysis: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for CenIA/vit-mae-base-finetuned-mimic\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=0\n",
      "checkpoint_names = ['checkpoint_30_chf1+chf1+cD+ema+orcc+qlf1+qlf1+wmmp=0.5813.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/checkpoint_30_chf1+chf1+cD+ema+orcc+qlf1+qlf1+wmmp=0.5813.pt\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/checkpoint_30_chf1+chf1+cD+ema+orcc+qlf1+qlf1+wmmp=0.5813.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = ground-truth\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053;report_eval_mode=ground-truth).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 32697, len(set(self.report_ids)) = 3258\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 32697, len(set(self.report_ids)) = 3258\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/vit-mae-base-ft-mimic+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 32697\n",
      "len(dataloader) = 205\n",
      "Evaluating model ...\n",
      "oracc 0.99732, chxlmicf1 0.59545, chxlmacf1 0.49740, chxlacc 0.71727, chxlrocaucmic 0.81931, chxlrocaucmac 0.76995, qlmacf1 0.22002, 165.25 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3258, len(gt_reports)=3258\n",
      "Cache successfully loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3258 texts ...\n",
      "Chexpert labeler: running a maximum of 6 concurrent processes over 6 chunks\n",
      "chunk: i=0, b=0, e=541, chunk_size=541\n",
      "chunk: i=1, b=541, e=1082, chunk_size=541\n",
      "chunk: i=2, b=1082, e=1623, chunk_size=541\n",
      "chunk: i=3, b=1623, e=2164, chunk_size=541\n",
      "chunk: i=4, b=2164, e=2705, chunk_size=541\n",
      "chunk: i=5, b=2705, e=3246, chunk_size=538\n",
      "\t#### process 1: running chexpert labeler over 541 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_180305_0.797598965242906_0.csv --output_path /data/labeler-output_20230124_180305_0.797598965242906_0.csv\n",
      "\t#### process 2: running chexpert labeler over 541 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_180305_0.797598965242906_1.csv --output_path /data/labeler-output_20230124_180305_0.797598965242906_1.csv\n",
      "\t#### process 3: running chexpert labeler over 541 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_180305_0.797598965242906_2.csv --output_path /data/labeler-output_20230124_180305_0.797598965242906_2.csv\n",
      "\t#### process 4: running chexpert labeler over 541 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_180305_0.797598965242906_3.csv --output_path /data/labeler-output_20230124_180305_0.797598965242906_3.csv\n",
      "\t#### process 5: running chexpert labeler over 541 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_180305_0.797598965242906_4.csv --output_path /data/labeler-output_20230124_180305_0.797598965242906_4.csv\n",
      "\t#### process 6: running chexpert labeler over 538 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_180305_0.797598965242906_5.csv --output_path /data/labeler-output_20230124_180305_0.797598965242906_5.csv\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t**** process 1 finished, elapsed time = 423.54464077949524\n",
      "\t**** process 2 finished, elapsed time = 423.5448200702667\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 3 finished, elapsed time = 440.1987655162811\n",
      "\t**** process 4 finished, elapsed time = 440.1988878250122\n",
      "\t**** process 5 finished, elapsed time = 440.1989667415619\n",
      "\t**** process 6 finished, elapsed time = 440.19903659820557\n",
      "Report-level metrics successfully saved to /mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"ground-truth\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 3 \\\n",
    "        --max-processes-for-chexpert-labeler 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script's arguments:\n",
      "   checkpoint_folder: /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp\n",
      "   eval_mode: chexpert-labels\n",
      "   n_questions_per_report: None\n",
      "   qclass_threshold: None\n",
      "   batch_size: 160\n",
      "   device: GPU\n",
      "   num_workers: 3\n",
      "   answer_decoding: greedy-search\n",
      "   eval_checkpoint_folder: None\n",
      "   precomputed_question_probs_path: None\n",
      "   precomputed_question_thresholds_path: None\n",
      "   use_random_image: False\n",
      "   eval_iuxray: False\n",
      "   eval_mimiccxr: True\n",
      "   use_amp: False\n",
      "   max_processes_for_chexpert_labeler: 4\n",
      "   save_for_error_analysis: False\n",
      "----- Evaluating model ------\n",
      "metadata loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/metadata.json\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m1) \u001b[0m\u001b[34mdevice =\u001b[0m \u001b[34mcuda\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m2) \u001b[0m\u001b[34mLoading iuxray and mimiccxr QA adapted reports ...\u001b[0m\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m3) \u001b[0m\u001b[34mInitializing tokenizer ...\u001b[0m\n",
      "Loading /mnt/data/pamessina/workspaces/medvqa-workspace/cache/vocab(min_freq=10;mode=report;qa_adapted_reports__20220904_091601.json;qa_adapted_reports__20220904_095810.json;_mnt_data_padchest_PADCHEST_chest_x_ray_images_labels_160K_01.02.19.csv).pkl ...\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m4) \u001b[0m\u001b[34mEstimating maximum answer length ...\u001b[0m\n",
      "max_answer_length = 15\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m5) \u001b[0m\u001b[34mDefining image transform ...\u001b[0m\n",
      "Using Huggingface ViT model transform for CenIA/vit-mae-base-finetuned-mimic\n",
      "mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225), image_size = (224, 224), use_center_crop = False\n",
      "Returning transform without augmentation\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m6) \u001b[0m\u001b[34mDefining collate_batch_fn ...\u001b[0m\n",
      "get_vqa_collate_batch_fn(): dataset_id=1, one_hot_question_offset=97\n",
      "checkpoint_names = ['checkpoint_30_chf1+chf1+cD+ema+orcc+qlf1+qlf1+wmmp=0.5813.pt']\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m7) \u001b[0m\u001b[34mLoading model from checkpoint ...\u001b[0m\n",
      "checkpoint_path =  /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/checkpoint_30_chf1+chf1+cD+ema+orcc+qlf1+qlf1+wmmp=0.5813.pt\n",
      "pretrained_checkpoint_path = /mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/checkpoint_30_chf1+chf1+cD+ema+orcc+qlf1+qlf1+wmmp=0.5813.pt\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m8) \u001b[0m\u001b[34mCreating MIMIC-CXR vqa evaluator ...\u001b[0m\n",
      "report_eval_mode = chexpert-labels\n",
      "Checking if data is already cached in path /mnt/data/pamessina/workspaces/medvqa-workspace/cache/mimiccxr/mimiccxr_preprocessed_test_data__(dataset=qa_adapted_reports__20220904_095810.json;tokenizer=4871,39534,3343246773703667053;report_eval_mode=chexpert-labels).pkl ...\n",
      "\tYes, it is, data successfully loaded :)\n",
      "batch_size = 160\n",
      "len(self.report_ids) = 45766, len(set(self.report_ids)) = 3269\n",
      "VQA_Evaluator():\n",
      "  len(self.test_indices) = 45766, len(set(self.report_ids)) = 3269\n",
      "generating test dataset ...\n",
      "generating test dataloader ...\n",
      "done!\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m9) \u001b[0m\u001b[34mCreating instance of OpenEndedVQA model ...\u001b[0m\n",
      "OpenEndedVQA():\n",
      "  image_encoder_pretrained_weights_path None\n",
      "  self.global_feat_size = 768\n",
      "  n_questions = 350\n",
      "  n_questions_aux_task = 97\n",
      "  question_encoding = one-hot\n",
      "  answer_decoding = transformer\n",
      "  visual_input_mode = raw-image\n",
      "  name = oevqa(CenIA/vit-mae-base-ft-mimic+onehot+transf)\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m10) \u001b[0m\u001b[34mCreating evaluator engine ...\u001b[0m\n",
      "get_engine(): shift_answer=False\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m11) \u001b[0m\u001b[34mAttaching metrics, losses, timer and events to engines ...\u001b[0m\n",
      "\n",
      "========================\n",
      "\u001b[34m--------------------------------------------------\u001b[0m\n",
      "\u001b[34m12) \u001b[0m\u001b[34mRunning evaluator engine on MIMIC-CXR test split ...\u001b[0m\n",
      "len(dataset) = 45766\n",
      "len(dataloader) = 287\n",
      "Evaluating model ...\n",
      "oracc 0.99704, chxlmicf1 0.57284, chxlmacf1 0.47797, chxlacc 0.71193, chxlrocaucmic 0.81732, chxlrocaucmac 0.76581, qlmacf1 0.20283, 232.73 secs\n",
      "\u001b[34mComputing metrics ...\u001b[0m\n",
      "recovered reports: len(gen_reports)=3269, len(gt_reports)=3269\n",
      "Cache successfully loaded from /mnt/data/pamessina/workspaces/medvqa-workspace/cache/chexpert_labeler_cache.pkl\n",
      "(*) Chexpert: labeling 3269 texts ...\n",
      "All labels found in cache, no need to invoke chexpert labeler\n",
      "(*) Chexpert: labeling 3269 texts ...\n",
      "Chexpert labeler: running a maximum of 4 concurrent processes over 4 chunks\n",
      "chunk: i=0, b=0, e=155, chunk_size=155\n",
      "chunk: i=1, b=155, e=310, chunk_size=155\n",
      "chunk: i=2, b=310, e=465, chunk_size=155\n",
      "chunk: i=3, b=465, e=620, chunk_size=152\n",
      "\t#### process 1: running chexpert labeler over 155 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_181504_0.96761869102811_0.csv --output_path /data/labeler-output_20230124_181504_0.96761869102811_0.csv\n",
      "\t#### process 2: running chexpert labeler over 155 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_181504_0.96761869102811_1.csv --output_path /data/labeler-output_20230124_181504_0.96761869102811_1.csv\n",
      "\t#### process 3: running chexpert labeler over 155 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_181504_0.96761869102811_2.csv --output_path /data/labeler-output_20230124_181504_0.96761869102811_2.csv\n",
      "\t#### process 4: running chexpert labeler over 152 texts ...\n",
      "\tCommand = docker run -v /mnt/data/pamessina/workspaces/medvqa-workspace/tmp/chexpert-labeler:/data chexpert-labeler:latest python label.py --reports_path /data/labeler-input_20230124_181504_0.96761869102811_3.csv --output_path /data/labeler-output_20230124_181504_0.96761869102811_3.csv\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 1 finished, elapsed time = 74.71436524391174\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 2 finished, elapsed time = 76.187903881073\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "Generating LALR tables\n",
      "Downloading 'http://search.maven.org/remotecontent?filepath=edu/stanford/nlp/stanford-corenlp/3.5.2/stanford-corenlp-3.5.2.jar' -> '/root/.local/share/pystanforddeps/stanford-corenlp-3.5.2.jar'\n",
      "\t**** process 3 finished, elapsed time = 77.01503610610962\n",
      "\t**** process 4 finished, elapsed time = 77.06100487709045\n",
      "Report-level metrics successfully saved to /mnt/data/pamessina/workspaces/medvqa-workspace/results/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl\n"
     ]
    }
   ],
   "source": [
    "!python ../eval_report_generation.py \\\n",
    "        --checkpoint-folder \"/mnt/data/pamessina/workspaces/medvqa-workspace/models/vqa/20230124_154438_mim+mim(chex)_oevqa(CenIA-vit-mae-base-ft-mimic+onehot+transf)_visenc-pretr=0_dws=1.0,0.8_medtok_orien_chx_ql_amp\" \\\n",
    "        --eval-mode \"chexpert-labels\" \\\n",
    "        --no-iuxray \\\n",
    "        --batch-size 160 \\\n",
    "        --num-workers 3 \\\n",
    "        --max-processes-for-chexpert-labeler 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ** Not cached key: ('/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels;rand-img).pkl', 1665584268.3134632)\n",
      "Report level metrics updated and saved to /home/pamessina/medvqa-workspace/cache/report_level_metrics_cache.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics_path</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>cD</th>\n",
       "      <th>rg-L</th>\n",
       "      <th>met</th>\n",
       "      <th>mdcmp</th>\n",
       "      <th>wmdcmp</th>\n",
       "      <th>chxlabf1(hard)</th>\n",
       "      <th>p(micro)</th>\n",
       "      <th>r(micro)</th>\n",
       "      <th>f1(micro)</th>\n",
       "      <th>p(macro)</th>\n",
       "      <th>r(macro)</th>\n",
       "      <th>f1(macro)</th>\n",
       "      <th>acc</th>\n",
       "      <th>p(NF)</th>\n",
       "      <th>p(EC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.311050</td>\n",
       "      <td>0.182289</td>\n",
       "      <td>0.105447</td>\n",
       "      <td>0.060095</td>\n",
       "      <td>0.137949</td>\n",
       "      <td>0.264437</td>\n",
       "      <td>0.239679</td>\n",
       "      <td>0.176180</td>\n",
       "      <td>0.159286</td>\n",
       "      <td>0.642122</td>\n",
       "      <td>0.624808</td>\n",
       "      <td>0.793620</td>\n",
       "      <td>0.699169</td>\n",
       "      <td>0.533453</td>\n",
       "      <td>0.677922</td>\n",
       "      <td>0.592004</td>\n",
       "      <td>0.831031</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>0.503369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.297485</td>\n",
       "      <td>0.168769</td>\n",
       "      <td>0.094768</td>\n",
       "      <td>0.049226</td>\n",
       "      <td>0.040825</td>\n",
       "      <td>0.200204</td>\n",
       "      <td>0.188816</td>\n",
       "      <td>0.086914</td>\n",
       "      <td>0.066313</td>\n",
       "      <td>0.479217</td>\n",
       "      <td>0.375769</td>\n",
       "      <td>0.848442</td>\n",
       "      <td>0.520855</td>\n",
       "      <td>0.366841</td>\n",
       "      <td>0.787875</td>\n",
       "      <td>0.440346</td>\n",
       "      <td>0.614714</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.312474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.320108</td>\n",
       "      <td>0.187390</td>\n",
       "      <td>0.107688</td>\n",
       "      <td>0.060916</td>\n",
       "      <td>0.143051</td>\n",
       "      <td>0.267179</td>\n",
       "      <td>0.241110</td>\n",
       "      <td>0.177480</td>\n",
       "      <td>0.159992</td>\n",
       "      <td>0.633187</td>\n",
       "      <td>0.601815</td>\n",
       "      <td>0.799291</td>\n",
       "      <td>0.686636</td>\n",
       "      <td>0.528748</td>\n",
       "      <td>0.674958</td>\n",
       "      <td>0.585289</td>\n",
       "      <td>0.819499</td>\n",
       "      <td>0.528662</td>\n",
       "      <td>0.493682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.298004</td>\n",
       "      <td>0.168776</td>\n",
       "      <td>0.095184</td>\n",
       "      <td>0.050351</td>\n",
       "      <td>0.041335</td>\n",
       "      <td>0.200282</td>\n",
       "      <td>0.188707</td>\n",
       "      <td>0.087520</td>\n",
       "      <td>0.066866</td>\n",
       "      <td>0.481301</td>\n",
       "      <td>0.388255</td>\n",
       "      <td>0.818785</td>\n",
       "      <td>0.526738</td>\n",
       "      <td>0.372965</td>\n",
       "      <td>0.756064</td>\n",
       "      <td>0.439116</td>\n",
       "      <td>0.636848</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.309888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.303779</td>\n",
       "      <td>0.177621</td>\n",
       "      <td>0.101914</td>\n",
       "      <td>0.057489</td>\n",
       "      <td>0.122372</td>\n",
       "      <td>0.263362</td>\n",
       "      <td>0.241083</td>\n",
       "      <td>0.173110</td>\n",
       "      <td>0.156225</td>\n",
       "      <td>0.641499</td>\n",
       "      <td>0.609479</td>\n",
       "      <td>0.803367</td>\n",
       "      <td>0.693119</td>\n",
       "      <td>0.531462</td>\n",
       "      <td>0.684505</td>\n",
       "      <td>0.593475</td>\n",
       "      <td>0.823994</td>\n",
       "      <td>0.515306</td>\n",
       "      <td>0.500446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.296238</td>\n",
       "      <td>0.166488</td>\n",
       "      <td>0.094025</td>\n",
       "      <td>0.050064</td>\n",
       "      <td>0.040010</td>\n",
       "      <td>0.199703</td>\n",
       "      <td>0.188812</td>\n",
       "      <td>0.087040</td>\n",
       "      <td>0.066649</td>\n",
       "      <td>0.516385</td>\n",
       "      <td>0.433534</td>\n",
       "      <td>0.798867</td>\n",
       "      <td>0.562050</td>\n",
       "      <td>0.380492</td>\n",
       "      <td>0.706232</td>\n",
       "      <td>0.464667</td>\n",
       "      <td>0.692719</td>\n",
       "      <td>0.381356</td>\n",
       "      <td>0.313268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.307875</td>\n",
       "      <td>0.180749</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.059246</td>\n",
       "      <td>0.131478</td>\n",
       "      <td>0.265232</td>\n",
       "      <td>0.241943</td>\n",
       "      <td>0.175444</td>\n",
       "      <td>0.158589</td>\n",
       "      <td>0.649519</td>\n",
       "      <td>0.632621</td>\n",
       "      <td>0.792556</td>\n",
       "      <td>0.703615</td>\n",
       "      <td>0.552388</td>\n",
       "      <td>0.663482</td>\n",
       "      <td>0.598003</td>\n",
       "      <td>0.834802</td>\n",
       "      <td>0.525714</td>\n",
       "      <td>0.480642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.294988</td>\n",
       "      <td>0.164696</td>\n",
       "      <td>0.092501</td>\n",
       "      <td>0.049122</td>\n",
       "      <td>0.039515</td>\n",
       "      <td>0.199351</td>\n",
       "      <td>0.188057</td>\n",
       "      <td>0.086687</td>\n",
       "      <td>0.066477</td>\n",
       "      <td>0.533446</td>\n",
       "      <td>0.464463</td>\n",
       "      <td>0.778683</td>\n",
       "      <td>0.581861</td>\n",
       "      <td>0.389259</td>\n",
       "      <td>0.652986</td>\n",
       "      <td>0.471842</td>\n",
       "      <td>0.723769</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.320490</td>\n",
       "      <td>0.186891</td>\n",
       "      <td>0.107263</td>\n",
       "      <td>0.060948</td>\n",
       "      <td>0.146676</td>\n",
       "      <td>0.267078</td>\n",
       "      <td>0.239056</td>\n",
       "      <td>0.177343</td>\n",
       "      <td>0.160046</td>\n",
       "      <td>0.648856</td>\n",
       "      <td>0.652839</td>\n",
       "      <td>0.753035</td>\n",
       "      <td>0.699366</td>\n",
       "      <td>0.560542</td>\n",
       "      <td>0.641684</td>\n",
       "      <td>0.591848</td>\n",
       "      <td>0.839823</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.551980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.297630</td>\n",
       "      <td>0.167762</td>\n",
       "      <td>0.094945</td>\n",
       "      <td>0.050615</td>\n",
       "      <td>0.040754</td>\n",
       "      <td>0.200426</td>\n",
       "      <td>0.190390</td>\n",
       "      <td>0.087720</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.517402</td>\n",
       "      <td>0.437421</td>\n",
       "      <td>0.792050</td>\n",
       "      <td>0.563591</td>\n",
       "      <td>0.389765</td>\n",
       "      <td>0.699889</td>\n",
       "      <td>0.470728</td>\n",
       "      <td>0.697242</td>\n",
       "      <td>0.418033</td>\n",
       "      <td>0.311558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.268723</td>\n",
       "      <td>0.146573</td>\n",
       "      <td>0.081271</td>\n",
       "      <td>0.045096</td>\n",
       "      <td>0.098529</td>\n",
       "      <td>0.229115</td>\n",
       "      <td>0.200962</td>\n",
       "      <td>0.133664</td>\n",
       "      <td>0.120104</td>\n",
       "      <td>0.523469</td>\n",
       "      <td>0.515905</td>\n",
       "      <td>0.659637</td>\n",
       "      <td>0.578984</td>\n",
       "      <td>0.479568</td>\n",
       "      <td>0.515411</td>\n",
       "      <td>0.422007</td>\n",
       "      <td>0.762650</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.329958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.165011</td>\n",
       "      <td>0.090006</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>0.133457</td>\n",
       "      <td>0.237674</td>\n",
       "      <td>0.206644</td>\n",
       "      <td>0.145296</td>\n",
       "      <td>0.131804</td>\n",
       "      <td>0.493320</td>\n",
       "      <td>0.504204</td>\n",
       "      <td>0.579265</td>\n",
       "      <td>0.539134</td>\n",
       "      <td>0.407133</td>\n",
       "      <td>0.428186</td>\n",
       "      <td>0.347968</td>\n",
       "      <td>0.754977</td>\n",
       "      <td>0.200873</td>\n",
       "      <td>0.272199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.297319</td>\n",
       "      <td>0.165141</td>\n",
       "      <td>0.089091</td>\n",
       "      <td>0.045275</td>\n",
       "      <td>0.040234</td>\n",
       "      <td>0.197957</td>\n",
       "      <td>0.190986</td>\n",
       "      <td>0.081018</td>\n",
       "      <td>0.062569</td>\n",
       "      <td>0.156631</td>\n",
       "      <td>0.192219</td>\n",
       "      <td>0.157714</td>\n",
       "      <td>0.173265</td>\n",
       "      <td>0.060987</td>\n",
       "      <td>0.196267</td>\n",
       "      <td>0.062148</td>\n",
       "      <td>0.636346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         metrics_path        b1        b2  \\\n",
       "0   /home/pamessina/medvqa-workspace/results/vqa/2...  0.311050  0.182289   \n",
       "1   /home/pamessina/medvqa-workspace/results/vqa/2...  0.297485  0.168769   \n",
       "2   /home/pamessina/medvqa-workspace/results/vqa/2...  0.320108  0.187390   \n",
       "3   /home/pamessina/medvqa-workspace/results/vqa/2...  0.298004  0.168776   \n",
       "4   /home/pamessina/medvqa-workspace/results/vqa/2...  0.303779  0.177621   \n",
       "5   /home/pamessina/medvqa-workspace/results/vqa/2...  0.296238  0.166488   \n",
       "6   /home/pamessina/medvqa-workspace/results/vqa/2...  0.307875  0.180749   \n",
       "7   /home/pamessina/medvqa-workspace/results/vqa/2...  0.294988  0.164696   \n",
       "8   /home/pamessina/medvqa-workspace/results/vqa/2...  0.320490  0.186891   \n",
       "9   /home/pamessina/medvqa-workspace/results/vqa/2...  0.297630  0.167762   \n",
       "10  /home/pamessina/medvqa-workspace/results/vqa/2...  0.268723  0.146573   \n",
       "11  /home/pamessina/medvqa-workspace/results/vqa/2...  0.296500  0.165011   \n",
       "12  /home/pamessina/medvqa-workspace/results/vqa/2...  0.297319  0.165141   \n",
       "\n",
       "          b3        b4        cD      rg-L       met     mdcmp    wmdcmp  \\\n",
       "0   0.105447  0.060095  0.137949  0.264437  0.239679  0.176180  0.159286   \n",
       "1   0.094768  0.049226  0.040825  0.200204  0.188816  0.086914  0.066313   \n",
       "2   0.107688  0.060916  0.143051  0.267179  0.241110  0.177480  0.159992   \n",
       "3   0.095184  0.050351  0.041335  0.200282  0.188707  0.087520  0.066866   \n",
       "4   0.101914  0.057489  0.122372  0.263362  0.241083  0.173110  0.156225   \n",
       "5   0.094025  0.050064  0.040010  0.199703  0.188812  0.087040  0.066649   \n",
       "6   0.104167  0.059246  0.131478  0.265232  0.241943  0.175444  0.158589   \n",
       "7   0.092501  0.049122  0.039515  0.199351  0.188057  0.086687  0.066477   \n",
       "8   0.107263  0.060948  0.146676  0.267078  0.239056  0.177343  0.160046   \n",
       "9   0.094945  0.050615  0.040754  0.200426  0.190390  0.087720  0.067200   \n",
       "10  0.081271  0.045096  0.098529  0.229115  0.200962  0.133664  0.120104   \n",
       "11  0.090006  0.049275  0.133457  0.237674  0.206644  0.145296  0.131804   \n",
       "12  0.089091  0.045275  0.040234  0.197957  0.190986  0.081018  0.062569   \n",
       "\n",
       "    chxlabf1(hard)  p(micro)  r(micro)  f1(micro)  p(macro)  r(macro)  \\\n",
       "0         0.642122  0.624808  0.793620   0.699169  0.533453  0.677922   \n",
       "1         0.479217  0.375769  0.848442   0.520855  0.366841  0.787875   \n",
       "2         0.633187  0.601815  0.799291   0.686636  0.528748  0.674958   \n",
       "3         0.481301  0.388255  0.818785   0.526738  0.372965  0.756064   \n",
       "4         0.641499  0.609479  0.803367   0.693119  0.531462  0.684505   \n",
       "5         0.516385  0.433534  0.798867   0.562050  0.380492  0.706232   \n",
       "6         0.649519  0.632621  0.792556   0.703615  0.552388  0.663482   \n",
       "7         0.533446  0.464463  0.778683   0.581861  0.389259  0.652986   \n",
       "8         0.648856  0.652839  0.753035   0.699366  0.560542  0.641684   \n",
       "9         0.517402  0.437421  0.792050   0.563591  0.389765  0.699889   \n",
       "10        0.523469  0.515905  0.659637   0.578984  0.479568  0.515411   \n",
       "11        0.493320  0.504204  0.579265   0.539134  0.407133  0.428186   \n",
       "12        0.156631  0.192219  0.157714   0.173265  0.060987  0.196267   \n",
       "\n",
       "    f1(macro)       acc     p(NF)     p(EC)  \n",
       "0    0.592004  0.831031  0.460674  0.503369  \n",
       "1    0.440346  0.614714  0.450000  0.312474  \n",
       "2    0.585289  0.819499  0.528662  0.493682  \n",
       "3    0.439116  0.636848  0.448276  0.309888  \n",
       "4    0.593475  0.823994  0.515306  0.500446  \n",
       "5    0.464667  0.692719  0.381356  0.313268  \n",
       "6    0.598003  0.834802  0.525714  0.480642  \n",
       "7    0.471842  0.723769  0.363636  0.333692  \n",
       "8    0.591848  0.839823  0.479167  0.551980  \n",
       "9    0.470728  0.697242  0.418033  0.311558  \n",
       "10   0.422007  0.762650  0.247525  0.329958  \n",
       "11   0.347968  0.754977  0.200873  0.272199  \n",
       "12   0.062148  0.636346  0.000000  0.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_report_level_metrics_dataframe([\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_report=20;qclass_threshold=0.5;chkpt=20220827_134655).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_rep=20;qclass_thr=0.5;probs=20220827_134655).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_rep=20;qclass_thr=0.5;probs=20220907_084600;epoch=162).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_rep=20;qclass_thr=0.5;probs=20220907_084600;epoch=568).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_rep=30;qclass_thr=0.4712;probs=multimodal;epoch=-1).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_rep=30;qclass_thr=0.4756;probs=multimodal;epoch=-1).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_rep=30;ensemble=(n=4,score=0.9137,t=20220914_063812)).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert+qclass;n_q_per_rep=30;ensemble=(n=4,score=0.9137,t=20220914_063812)).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220919_011422_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220919_011422_mim+mim(chex)+iu+iu(chex)+chexp(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220919_140350_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220919_140350_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220920_184735_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+lstm)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220920_184735_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+lstm)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220920_132652_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "#     '/home/pamessina/medvqa-workspace/results/vqa/20220920_132652_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220925_181231_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220925_181231_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220925_174700_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220925_174700_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220926_004746_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220926_004746_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220926_074409_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220926_074409_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220926_073839_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220926_073839_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-bp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220926_074409_mim+mim(chex)+iu+iu(chex)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth;rand-img).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220926_004746_mim+mim(chex)+iu+iu(chex)+chexp(vqa)+cxr14(vqa)+vinbig(vqa)_oevqa(CenIA-clip-vte-vit-lp16bcbf+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16,0.5,0.4,0.4_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth;rand-img).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=chexpert-labels;rand-img).pkl',\n",
    "])\n",
    "df[df.columns[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ** Not cached key: ('/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_rep=20;qclass_thr=0.5;probs=20220827_134655).pkl', 1662580065.1798313)\n",
      "Report level metrics updated and saved to /home/pamessina/medvqa-workspace/cache/report_level_metrics_cache.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics_path</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>cD</th>\n",
       "      <th>rg-L</th>\n",
       "      <th>met</th>\n",
       "      <th>mdcmp</th>\n",
       "      <th>wmdcmp</th>\n",
       "      <th>chxlabf1(hard)</th>\n",
       "      <th>p(micro)</th>\n",
       "      <th>r(micro)</th>\n",
       "      <th>f1(micro)</th>\n",
       "      <th>p(macro)</th>\n",
       "      <th>r(macro)</th>\n",
       "      <th>f1(macro)</th>\n",
       "      <th>acc</th>\n",
       "      <th>p(NF)</th>\n",
       "      <th>p(EC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.160418</td>\n",
       "      <td>0.087716</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.155766</td>\n",
       "      <td>0.160804</td>\n",
       "      <td>0.086769</td>\n",
       "      <td>0.071221</td>\n",
       "      <td>0.466409</td>\n",
       "      <td>0.416401</td>\n",
       "      <td>0.686019</td>\n",
       "      <td>0.518240</td>\n",
       "      <td>0.309865</td>\n",
       "      <td>0.510130</td>\n",
       "      <td>0.373347</td>\n",
       "      <td>0.691824</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.269763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.310955</td>\n",
       "      <td>0.184470</td>\n",
       "      <td>0.105573</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>0.153280</td>\n",
       "      <td>0.264432</td>\n",
       "      <td>0.233540</td>\n",
       "      <td>0.177028</td>\n",
       "      <td>0.158837</td>\n",
       "      <td>0.666134</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.796518</td>\n",
       "      <td>0.719410</td>\n",
       "      <td>0.595590</td>\n",
       "      <td>0.675522</td>\n",
       "      <td>0.622770</td>\n",
       "      <td>0.848895</td>\n",
       "      <td>0.563291</td>\n",
       "      <td>0.527668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/pamessina/medvqa-workspace/results/vqa/2...</td>\n",
       "      <td>0.171091</td>\n",
       "      <td>0.096853</td>\n",
       "      <td>0.052650</td>\n",
       "      <td>0.027238</td>\n",
       "      <td>0.021405</td>\n",
       "      <td>0.169709</td>\n",
       "      <td>0.177139</td>\n",
       "      <td>0.100769</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.515177</td>\n",
       "      <td>0.479922</td>\n",
       "      <td>0.715500</td>\n",
       "      <td>0.574499</td>\n",
       "      <td>0.385841</td>\n",
       "      <td>0.561077</td>\n",
       "      <td>0.431254</td>\n",
       "      <td>0.743915</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.326260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        metrics_path        b1        b2  \\\n",
       "0  /home/pamessina/medvqa-workspace/results/vqa/2...  0.160418  0.087716   \n",
       "1  /home/pamessina/medvqa-workspace/results/vqa/2...  0.310955  0.184470   \n",
       "2  /home/pamessina/medvqa-workspace/results/vqa/2...  0.171091  0.096853   \n",
       "\n",
       "         b3        b4        cD      rg-L       met     mdcmp    wmdcmp  \\\n",
       "0  0.046617  0.023529  0.016854  0.155766  0.160804  0.086769  0.071221   \n",
       "1  0.105573  0.058011  0.153280  0.264432  0.233540  0.177028  0.158837   \n",
       "2  0.052650  0.027238  0.021405  0.169709  0.177139  0.100769  0.085600   \n",
       "\n",
       "   chxlabf1(hard)  p(micro)  r(micro)  f1(micro)  p(macro)  r(macro)  \\\n",
       "0        0.466409  0.416401  0.686019   0.518240  0.309865  0.510130   \n",
       "1        0.666134  0.655914  0.796518   0.719410  0.595590  0.675522   \n",
       "2        0.515177  0.479922  0.715500   0.574499  0.385841  0.561077   \n",
       "\n",
       "   f1(macro)       acc     p(NF)     p(EC)  \n",
       "0   0.373347  0.691824  0.100000  0.269763  \n",
       "1   0.622770  0.848895  0.563291  0.527668  \n",
       "2   0.431254  0.743915  0.370370  0.326260  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_report_level_metrics_dataframe([\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_report=20;qclass_threshold=0.5;chkpt=20220827_134655).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=ground-truth).pkl',\n",
    "    '/home/pamessina/medvqa-workspace/results/vqa/20220827_134655_mim+mim(chex)+iu+iu(chex)_oevqa(dense121+onehot+transf)_visenc-pretr=0_dws=1.0,0.8,0.2,0.16_medtok_orien_chx_ql_amp/mimiccxr_report_level_metrics(eval_mode=question-classification;n_q_per_rep=20;qclass_thr=0.5;probs=20220827_134655).pkl',\n",
    "])\n",
    "df[df.columns[:20]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
